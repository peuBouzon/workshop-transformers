{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eedaaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from trainer import Trainer\n",
    "from tokenizer import MostFrequentWordsTokenizer\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import MultiHeadAttention, FeedForward\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596bcc8",
   "metadata": {},
   "source": [
    "### Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09c66185",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 512\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "MAX_EPOCHS = 25\n",
    "EVAL_INTERVAL = 100\n",
    "BATCH_SIZE = 64\n",
    "BLOCK_SIZE = 256\n",
    "LEARNING_RATE = 1e-5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe2538",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b324f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/skincancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "635f56c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patient History: Age: 8, Lesion region: arm, Lesion grew: false, Lesion itch: false, Lesion bled: false, Lesion hurt: false, Lesion changed: false, Lesion elevation: false.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eaf83005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnostic\n",
       "BCC    845\n",
       "ACK    730\n",
       "NEV    244\n",
       "SEK    235\n",
       "SCC    192\n",
       "MEL     52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnostic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c29f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'diagnostic'] = \\\n",
    "df['diagnostic'].map({\n",
    "  'BCC': 'malignant',\n",
    "  'SCC': 'malignant',\n",
    "  'ACK': 'benign',\n",
    "  'NEV': 'benign',\n",
    "  'SEK': 'benign',\n",
    "  'MEL': 'malignant'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mapping from diagnostic strings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "109d2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(df['diagnostic'].unique())\n",
    "label_to_int = {label: i for i, label in enumerate(labels)}\n",
    "int_to_label = {i: label for label, i in label_to_int.items()}\n",
    "df['label'] = df['diagnostic'].map(label_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77327b",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e6aa095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1838\n",
      "Validation set size: 460\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(labels)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df['sentence'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc1899",
   "metadata": {},
   "source": [
    "### Simple Word-Level Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e9e55e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size: 190\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MostFrequentWordsTokenizer(vocab_size=VOCAB_SIZE)\n",
    "tokenizer.build_vocab(X_train)\n",
    "print(f\"\\nVocabulary size: {tokenizer.get_vocab_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5762555",
   "metadata": {},
   "source": [
    "### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c7d430d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinLesionDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        token_ids = self.tokenizer.encode(['[CLS]']) + token_ids\n",
    "        token_ids = token_ids[:self.max_len]\n",
    "\n",
    "        id_pad_token = self.tokenizer.encode(['[PAD]'])\n",
    "        padding_len = self.max_len - len(token_ids)\n",
    "        token_ids = token_ids + id_pad_token * padding_len\n",
    "        attention_mask = [1 if id != id_pad_token else 0 for id in token_ids]\n",
    "        attention_mask = torch.tensor(attention_mask, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "            'mask': attention_mask,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "train_dataset = SkinLesionDataset(X_train, y_train, tokenizer, BLOCK_SIZE)\n",
    "val_dataset = SkinLesionDataset(X_val, y_val, tokenizer, BLOCK_SIZE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "49acfb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ff = FeedForward(d_model, ff_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_output = self.attention(x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.ff(x)\n",
    "        return self.norm2(x + self.dropout(ff_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2bf99847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBERT(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, num_classes, max_len, dropout):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_len, d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, n_heads, d_model * 4, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(d_model, num_classes)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_model])).to(DEVICE)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        batch_size, seq_len = src.shape\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(DEVICE)\n",
    "        tok_emb = self.token_embedding(src) * self.scale\n",
    "        pos_emb = self.position_embedding(pos)\n",
    "        x = self.dropout(tok_emb + pos_emb)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        cls_output = x[:, 0, :]\n",
    "        return self.fc_out(cls_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "01b0372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 01 | Train Loss: 0.720 | Val. Loss: 0.700 | Val. Recall: 48.97%\n",
      "Epoch: 02 | Train Loss: 0.689 | Val. Loss: 0.666 | Val. Recall: 58.60%\n",
      "Epoch: 03 | Train Loss: 0.675 | Val. Loss: 0.629 | Val. Recall: 71.32%\n",
      "Epoch: 04 | Train Loss: 0.655 | Val. Loss: 0.586 | Val. Recall: 79.75%\n",
      "Epoch: 05 | Train Loss: 0.626 | Val. Loss: 0.561 | Val. Recall: 79.75%\n",
      "Epoch: 06 | Train Loss: 0.604 | Val. Loss: 0.547 | Val. Recall: 79.75%\n",
      "Epoch: 07 | Train Loss: 0.571 | Val. Loss: 0.539 | Val. Recall: 79.75%\n",
      "Epoch: 08 | Train Loss: 0.538 | Val. Loss: 0.529 | Val. Recall: 79.75%\n",
      "Epoch: 09 | Train Loss: 0.502 | Val. Loss: 0.523 | Val. Recall: 79.75%\n",
      "Epoch: 10 | Train Loss: 0.473 | Val. Loss: 0.521 | Val. Recall: 79.75%\n",
      "Epoch: 11 | Train Loss: 0.455 | Val. Loss: 0.520 | Val. Recall: 79.75%\n",
      "Epoch: 12 | Train Loss: 0.446 | Val. Loss: 0.514 | Val. Recall: 79.75%\n",
      "Epoch: 13 | Train Loss: 0.421 | Val. Loss: 0.516 | Val. Recall: 79.75%\n",
      "Epoch: 14 | Train Loss: 0.418 | Val. Loss: 0.524 | Val. Recall: 79.75%\n",
      "Epoch: 15 | Train Loss: 0.407 | Val. Loss: 0.526 | Val. Recall: 79.75%\n",
      "Epoch: 16 | Train Loss: 0.423 | Val. Loss: 0.523 | Val. Recall: 79.75%\n",
      "Epoch: 17 | Train Loss: 0.414 | Val. Loss: 0.523 | Val. Recall: 79.75%\n",
      "Epoch: 18 | Train Loss: 0.395 | Val. Loss: 0.518 | Val. Recall: 79.75%\n",
      "Epoch: 19 | Train Loss: 0.405 | Val. Loss: 0.510 | Val. Recall: 79.75%\n",
      "Epoch: 20 | Train Loss: 0.393 | Val. Loss: 0.516 | Val. Recall: 79.75%\n",
      "Epoch: 21 | Train Loss: 0.391 | Val. Loss: 0.510 | Val. Recall: 79.75%\n",
      "Epoch: 22 | Train Loss: 0.385 | Val. Loss: 0.513 | Val. Recall: 79.75%\n",
      "Epoch: 23 | Train Loss: 0.390 | Val. Loss: 0.521 | Val. Recall: 79.75%\n",
      "Epoch: 24 | Train Loss: 0.391 | Val. Loss: 0.508 | Val. Recall: 79.75%\n",
      "Epoch: 25 | Train Loss: 0.381 | Val. Loss: 0.511 | Val. Recall: 79.75%\n",
      "\n",
      "Final Evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      0.60      0.75       242\n",
      "   malignant       0.69      1.00      0.82       218\n",
      "\n",
      "    accuracy                           0.79       460\n",
      "   macro avg       0.84      0.80      0.78       460\n",
      "weighted avg       0.85      0.79      0.78       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MiniBERT(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=N_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    max_len=BLOCK_SIZE,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "trainer = Trainer(device=DEVICE)\n",
    "trainer.fit(model,\n",
    "            LEARNING_RATE,\n",
    "            MAX_EPOCHS,\n",
    "            None,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            NUM_CLASSES,\n",
    "            int_to_label\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gandalf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
